{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f64a0d77-4a00-4524-a46a-64c20e4af7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source - changed\n",
    "import dlt\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be572261-0ad8-4237-90da-1e111b02e0c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema\n",
    "bank_schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"marital\", StringType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"default\", StringType(), True),\n",
    "    StructField(\"balance\", IntegerType(), True),\n",
    "    StructField(\"housing\", StringType(), True),\n",
    "    StructField(\"loan\", StringType(), True),\n",
    "    StructField(\"contact\", StringType(), True),\n",
    "    StructField(\"day\", IntegerType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"duration\", IntegerType(), True),\n",
    "    StructField(\"campaign\", IntegerType(), True),\n",
    "    StructField(\"pdays\", IntegerType(), True),\n",
    "    StructField(\"previous\", IntegerType(), True),\n",
    "    StructField(\"poutcome\", StringType(), True),\n",
    "    StructField(\"deposit\", StringType(), True)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ba0023b-bb9f-4f92-85e0-1e6fecbc2057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_bank_customers\",\n",
    "    comment=\"Raw CSV data ingested from S3 bucket\",\n",
    ")\n",
    "def bronze_bank_customers():\n",
    "    return (\n",
    "        spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(bank_schema)\n",
    "        .load(\"s3://aws-databricks-data-bucket-atin/data/bank-customers-raw\")\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4d85a5c-9784-4a27-8549-57f7b02d6829",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_bank_customers\",\n",
    "    comment=\"Cleaned and filtered customer data\"\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_age\", \"age IS NOT NULL AND age > 50\")\n",
    "@dlt.expect(\"non_negative_balance\", \"balance >= 0\")\n",
    "@dlt.expect(\"valid_deposit_value\", \"has_deposit IN ('yes', 'no')\")\n",
    "def silver_bank_customers():\n",
    "    df = dlt.read(\"bronze_bank_customers\")\n",
    "    \n",
    "    # Example transformation: filter out rows with null age or negative balance\n",
    "    return (\n",
    "        df.filter(\"age IS NOT NULL AND balance >= 0\")\n",
    "           .withColumnRenamed(\"deposit\", \"has_deposit\")\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c1fcea4-2b36-4fb6-8b7b-c3c25bc2af4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_deposit_summary\",\n",
    "    comment=\"Aggregated number of deposits by job\"\n",
    ")\n",
    "@dlt.expect(\"valid_job_not_null\", \"job IS NOT NULL AND job != 'unknown'\")\n",
    "@dlt.expect(\"valid_deposit_count\", \"num_deposits >= 0\")\n",
    "def gold_deposit_summary():\n",
    "    from pyspark.sql.functions import count, col\n",
    "    \n",
    "    df = dlt.read(\"silver_bank_customers\")\n",
    "    return (\n",
    "        df.filter(col(\"has_deposit\") == \"yes\")\n",
    "          .groupBy(\"job\")\n",
    "          .agg(count(\"*\").alias(\"num_deposits\"))\n",
    "          .orderBy(\"num_deposits\", ascending=False)\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dlt",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
